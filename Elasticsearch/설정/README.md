## ELK í™˜ê²½ ì„¤ì •

- Elasticsearch, Logstash, Kibana í™˜ê²½ ì„¤ì • ì •ë¦¬

---

### ğŸ“Œ í™˜ê²½
- Ubuntu Server 20.04 LTS 
    - m2.c4m8 (4Core, 8GB)
- Docker 
- Elasticsearch 7.17.8v
- Logstash 7.17.8v
- Kibana 7.17.8v

---

### ğŸ“Œ ê³µí†µ í™˜ê²½ ì„¤ì •

1. ELK ì´ë¯¸ì§€ pull
```
$ docker pull docker.elastic.co/elasticsearch/elasticsearch:7.17.8
$ docker pull docker.elastic.co/kibana/kibana:7.17.8
$ docker pull docker.elastic.co/logstash/logstash:7.17.8
```

2. docker-compose.yml
```yml
version: '2.2'
services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elastic
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    networks:
      - elastic
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.8
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
    networks:
      - elastic

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.8
    container_name: logstash
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - elastic
    depends_on:
      - es01

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.8
    container_name: kibana
    environment:
      SERVER_NAME: kibana.example.org
      ELASTICSEARCH_HOSTS: '["http://es01:9200","http://es02:9200","http://es03:9200"]'
    ports:
      - 5601:5601
    networks:
      - elastic

volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local

networks:
  elastic:
    driver: bridge
```

3. docker-compose.yml ì‹¤í–‰ 
```
$ docker-compose up -d  // ì‹¤í–‰
$ docker-compose down   // ì¢…ë£Œ
```

4. docker ëª…ë ¹ì–´
```
$ docker ps -a                                   // docker list
$ docker exec -u 0 -it {image ì´ë¦„} bash          // imageì— ê´€ë¦¬ì ê¶Œí™˜ìœ¼ë¡œ ì ‘ê·¼
$ docker exec -it {image ì´ë¦„} bash               // imageì— ì ‘ê·¼   
```

5. ê´€ë¦¬ì ê¶Œí•œì—ì„œ ëª…ë ¹ì–´ ë‹¤ìš´ë¡œë“œ
```
// es01, es02, es03, kibana, logstash ë‚´ë¶€ì—ì„œ ì‹¤í–‰
$ apt-get update && apt-get install vim && apt-get install wget
```

----


### ğŸ“Œ Elasticsearch ì„¤ì •
- docker-compose.ymlì—ì„œ ì§€ì •í•œ 3ê°œì˜ Elasticsearch nodeì— ëª¨ë‘ ì„¤ì •

1. Nori ë¶„ì„ê¸° ì„¤ì¹˜
```
$ ./bin/elasticsearch-plugin install analysis-nori
```

2. Jaso í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜
- Noriì™€ ë‹¤ë¥´ê²Œ ì˜¤í”ˆì†ŒìŠ¤ í”ŒëŸ¬ê·¸ì¸ ì‚¬ìš©
```
$ wget https://github.com/netcrazy/elasticsearch-jaso-analyzer/releases/download/v7.16.2/jaso-analyzer-plugin-7.16.2-plugin.zip
$ unzip jaso-analyzer-plugin-7.16.2-plugin.zip
$ vi plugin-descriptor.properties       // ë²„ì „ ë³€ê²½ (7.17.8ë¡œ ë³€ê²½)
$ zip jaso.zip elasticsearch-jaso-analyzer-7.16.2.jar log4j2.xml plugin-descriptor.properties
$ bin/elasticsearch-plugin install file:///usr/share/elasticsearch/jaso.zip     // í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜
$ rm jaso-analyzer-plugin-7.16.2-plugin.zip
$ rm jaso.zip
$ rm elasticsearch-jaso-analyzer-7.16.2.jar
$ rm log4j2.xml
$ rm plugin-descriptor.properties
```

3. Linux í•œêµ­ì–´ ì„¸íŒ…
```
$ vim /etc/vim/vimrc

// ì•„ë˜ ë‚´ìš©ì„ íŒŒì¼ ì•„ë˜ìª½ì— ì…ë ¥ í›„ ì €ì¥
set encoding=utf-8
set fileencodings=utf-8,cp949
```


4. ë™ì˜ì–´ ì‚¬ì „ ì„¸íŒ…
```
$ cd config
$ mkdir analysis
$ vi book_pub_synonym.txt

// *.txtì— ì•„ë˜ ë‚´ìš©ê³¼ ê°™ì´ ì €ì¥
java, ìë°”
spring, ìŠ¤í”„ë§
ì •ì²˜ê¸°, ì •ë³´ì²˜ë¦¬ê¸°ì‚¬
```

---

### ğŸ“Œ Logstash ì„¤ì •

1. mysql-connector ë‹¤ìš´
```
$ wget 'https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.18.tar.gz'
$ tar -xvf ./mysql-connector-java-8.0.18.tar.gz
$ rm -rf ./mysql-connector-java-8.0.18.tar.gz 
$ cp mysql-connector-java-8.0.18/mysql-connector-java-8.0.18.jar /usr/share/logstash/bin/{ì›í•˜ëŠ”ê²½íŒŒì¼ëª…}
$ mv ./mysql-connector-java-8.0.18/mysql-connector-java-8.0.18.jar ./lib/mysql-connector-java-8.0.18.jar 
$ rm -rf mysql-connector-java-8.0.18
```

--- 

### ğŸ“Œ ì¸ë±ìŠ¤, logstash ì„¤ì •

- ìƒí’ˆ ì¸ë±ìŠ¤
```
PUT /book_pub_product_dev
{
  "settings": {
    "index": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "analysis": {
        "filter": {
          "suggest_filter": {
            "type": "edge_ngram",
            "min_gram": 1,
            "max_gram": 50
          },
          "synonym_filter": {
            "type": "synonym",
            "synonyms_path": "analysis/book_pub_synonym.txt",
            "updateable": true
          }
        },
        "tokenizer": {
          "jaso_search_tokenizer": {
            "type": "jaso_tokenizer",
            "mistype": true,
            "chosung": false
          },
          "jaso_index_tokenizer": {
            "type": "jaso_tokenizer",
            "mistype": true,
            "chosung": true
          },
          "nori_t_discard": {
            "type": "nori_tokenizer",
            "decompound_mode": "discard"
          }
        },
        "analyzer": {
          "suggest_search_analyzer": {
            "type": "custom",
            "tokenizer": "jaso_search_tokenizer",
            "filter": [
              "synonym_filter"
            ]
          },
          "suggest_index_analyzer": {
            "type": "custom",
            "tokenizer": "jaso_index_tokenizer",
            "filter": [
              "suggest_filter",
              "remove_duplicates"
            ]
          },
          "nori_discard": {
            "tokenizer": "nori_t_discard",
            "filter": [
              "suggest_filter",
              "remove_duplicates"
            ]
          }
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "long"
      },
      "title": {
        "type": "keyword"
      },
      "titlenori": {
        "type": "text", 
        "analyzer": "nori_discard"
      },
      "titlejaso": {
        "type": "text", 
        "analyzer": "suggest_index_analyzer"
      },
      "salesprice": {
        "type": "long"
      },
      "salesrate": {
        "type": "integer"
      },
      "filepath": {
        "type": "keyword"
      }
    }
  }
}
```

- ê³ ê°ì„œë¹„ìŠ¤ ì¸ë±ìŠ¤
```
PUT /book_pub_cs_dev
{
  "settings": {
    "index": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "analysis": {
        "filter": {
          "suggest_filter": {
            "type": "edge_ngram",
            "min_gram": 1,
            "max_gram": 50
          }
        },
        "tokenizer": {
          "jaso_search_tokenizer": {
            "type": "jaso_tokenizer",
            "mistype": true,
            "chosung": false
          },
          "jaso_index_tokenizer": {
            "type": "jaso_tokenizer",
            "mistype": true,
            "chosung": true
          },
          "nori_t_discard": {
            "type": "nori_tokenizer",
            "decompound_mode": "discard"
          }
        },
        "analyzer": {
          "suggest_search_analyzer": {
            "type": "custom",
            "tokenizer": "jaso_search_tokenizer"
          },
          "suggest_index_analyzer": {
            "type": "custom",
            "tokenizer": "jaso_index_tokenizer",
            "filter": [
              "suggest_filter",
              "remove_duplicates"
            ]
          },
          "nori_discard": {
            "tokenizer": "nori_t_discard",
            "filter": [
              "suggest_filter",
              "remove_duplicates"
            ]
          }
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "csid": {
        "type": "integer"
      },
      "cscodename": {
        "type": "keyword"
      },
      "cstitle": {
        "type": "keyword"
      },
      "cstitlejaso": {
        "type": "text",
        "analyzer": "suggest_index_analyzer"
      },
      "cstitlenori": {
        "type": "text",
        "analyzer": "nori_discard"
      },
      "cscontentjaso": {
        "type": "text",
        "analyzer": "suggest_index_analyzer"
      },
      "cscontentnori": {
        "type": "text",
        "analyzer": "nori_discard"
      },
      "cscategory": {
        "type": "keyword"
      },
      "csdate": {
        "type": "date"
      }
    }
  }
}
```

- ìƒí’ˆ Logstash
```
input {
  jdbc {
        jdbc_driver_library => "/usr/share/logstash/bin/book-pub/mysql-connector-java-8.0.18.jar"
        jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
        jdbc_connection_string => "jdbc:mysql://133.186.151.141:3306/bookpub_shop_dev?serverTimezone=UTC"
        jdbc_user => "bookpub"
        jdbc_password => "3wX.DPUpjpdSn@d."
        use_column_value => true
        tracking_column => "p.product_number"
        last_run_metadata_path => "/usr/share/logstash/index_metadata/book_pub_product_dev.dat"
        statement => "SELECT      p.product_number AS id,
                                  p.product_title AS title,
                                  p.product_title AS titlejaso,
                                  p.product_title AS titlenori,
                                  p.product_sales_price AS salesprice,
                                  p.product_sales_rate AS salesrate,
                                  f.file_path AS filepath
                      FROM product AS p
                      LEFT JOIN file AS f on f.product_number = p.product_number
                      WHERE p.product_number >= :sql_last_value AND f.file_category = 'thumbnail' OR f.file_category is null ORDER BY p.product_number ASC"
        schedule => "* * * * *"
 }
}

filter {
  mutate {
    copy => { "id" => "[@metadata][_id]"}
    remove_field => ["@version", "@timestamp"] }
}

output {
  elasticsearch {
    hosts => ["133.186.210.108:9200"]
    index => "book_pub_product_dev"
    document_id => "%{[@metadata][_id]}"
    doc_as_upsert => true
    action => update
  }
 stdout {
    codec => rubydebug
 }
}
```

- ê³ ê° ì„œë¹„ìŠ¤ Logstash
```
input {
  jdbc {
        jdbc_driver_library => "/usr/share/logstash/bin/book-pub/mysql-connector-java-8.0.18.jar"
        jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
        jdbc_connection_string => "jdbc:mysql://133.186.151.141:3306/bookpub_shop_prod?serverTimezone=UTC"
        jdbc_user => "bookpub"
        jdbc_password => "3wX.DPUpjpdSn@d."
        use_column_value => true
        tracking_column => "cs.customer_service_number"
        last_run_metadata_path => "/usr/share/logstash/index_metadata/book_pub_cs_prod.dat"
        statement => "SELECT      cs.customer_service_number AS csid,
                                  csc.customer_service_state_code_info AS cscodename,
                                  cs.customer_service_title as cstitle,
                                  cs.customer_service_title as cstitlejaso,
                                  cs.customer_service_title as cstitlenori,
                                  cs.customer_service_content as cscontentjaso,
                                  cs.customer_service_content as cscontentnori,
                                  cs.customer_service_category as cscategory,
                                  cs.created_at as csdate
                        FROM customer_service AS cs
                        LEFT JOIN customer_service_state_code AS csc ON csc.customer_service_state_code_number = cs.customer_service_code_number
                      WHERE cs.customer_service_number >= :sql_last_value ORDER BY cs.customer_service_number ASC"
        schedule => "* * * * *"
 }
}

filter {
  mutate {
    copy => { "id" => "[@metadata][_id]"}
    remove_field => ["@version", "@timestamp"] }
}

output {
  elasticsearch {
    hosts => ["133.186.210.108:9200"]
    index => "book_pub_cs_prod"
    document_id => "%{[@metadata][_id]}"
    doc_as_upsert => true
    action => update
  }
 stdout {
    codec => rubydebug
 }
}
```

